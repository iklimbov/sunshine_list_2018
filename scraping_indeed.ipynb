{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThis used to scrape indeed.com for infromation for a number of companies.\\n\\nThe list of companies should be provided in the companies.csv (./data directory), with no index column.\\nExample:\\n    RBC\\n    TD bank\\n    Boston Pizza \\n\\nThe result will be placed in the ./data directory, in companies_with_indeed_data.csv\\nFile format:\\n    'company','work_life','salary','job_security','management','culture','ceo','ceo_details',\\n            'num_reviews','pay_details', 'num_employees', 'revinew','got_indeed_review'\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This used to scrape indeed.com for infromation for a number of companies.\n",
    "\n",
    "The list of companies should be provided in the companies.csv (./data directory), with no index column.\n",
    "Example:\n",
    "    RBC\n",
    "    TD bank\n",
    "    Boston Pizza \n",
    "\n",
    "The result will be placed in the ./data directory, in companies_with_indeed_data.csv\n",
    "File format:\n",
    "    'company','work_life','salary','job_security','management','culture','ceo','ceo_details',\n",
    "            'num_reviews','pay_details', 'num_employees', 'revinew','got_indeed_review'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.firefox.firefox_binary import FirefoxBinary\n",
    "import pandas as pd\n",
    "import requests\n",
    "import selenium.webdriver as webdriver\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape indeed for ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function is finding company on indeed, scrapes, \n",
    "returns array with the info.\n",
    "@company_name is the name of the company (ex: \"RBC\")\n",
    "'''\n",
    "\n",
    "def get_ratings(company_name):\n",
    "\n",
    "\n",
    "    try:\n",
    "        # search for company\n",
    "        driver.get(\"https://ca.indeed.com/companies\")\n",
    "        driver.find_element_by_id(\"search-by-company-input\").send_keys(company_name)\n",
    "        driver.find_element_by_id(\"cmp-discovery-cs-submit\").click()\n",
    "        \n",
    "        # if company found, open the company's page\n",
    "        elements = driver.find_elements_by_css_selector(\"div.cmp-company-tile-blue-name a\")\n",
    "        main_url =elements[0].get_attribute(\"href\")\n",
    "        driver.get(main_url)\n",
    "        \n",
    "        # start return verctor with just name of the company\n",
    "        all_ratings = [company_name]\n",
    "        \n",
    "        # find page elements\n",
    "        ratings = driver.find_elements_by_class_name(\"cmp-ReviewCategory-rating\")\n",
    "        cnt = driver.find_elements_by_class_name(\"cmp-CeoWidgetWithRating-subtext\")\n",
    "        ceo_appr = driver.find_elements_by_class_name(\"cmp-CeoWidgetWithRating-percent\")\n",
    "        num_reviews = driver.find_elements_by_class_name(\"cmp-ReviewAndRatingsStory-reviewsLink\")\n",
    "        if (ratings):\n",
    "            for r in ratings:\n",
    "                all_ratings.append(r.text)\n",
    "        else:\n",
    "            all_ratings+=(['','','','',''])\n",
    "        try:\n",
    "            all_ratings.append(ceo_appr[0].text)\n",
    "        except:\n",
    "            all_ratings.append('')\n",
    "        try:\n",
    "            all_ratings.append(cnt[0].text)\n",
    "        except:\n",
    "            all_ratings.append('')\n",
    "        try:\n",
    "            all_ratings.append(num_reviews[0].text)\n",
    "        except:\n",
    "            all_ratings.append('')\n",
    "        try:\n",
    "            salaries_url = main_url+\"/salaries\"\n",
    "            driver.get(salaries_url)\n",
    "            num_reviews = driver.find_elements_by_class_name(\"cmp-salary-footer-text\")\n",
    "            all_ratings.append(num_reviews[0].text)\n",
    "        except:\n",
    "            all_ratings.append('')\n",
    "        \n",
    "        # collect additional data (company size and revenue)\n",
    "        emp = '0'\n",
    "        rev = '0'\n",
    "        try:\n",
    "            about_url = main_url+\"/about\"\n",
    "            r = requests.get(about_url,\n",
    "                         headers={\n",
    "                             \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:62.0) Gecko/20100101 Firefox/62.0\"},\n",
    "                         timeout=10)\n",
    "            soup = BeautifulSoup(r.content, \"html5\")\n",
    "            ddd = soup.find(\"dl\", {\"id\": \"cmp-company-details-sidebar\"})\n",
    "            d1_data = ddd.find_all(\"dd\")\n",
    "            d2_data = ddd.find_all(\"dt\")\n",
    "\n",
    "            for name, item in zip(d2_data,d1_data):\n",
    "                if ('Employees' in name):\n",
    "                    emp = item\n",
    "                if ('Revenue' in name):\n",
    "                    rev = item\n",
    "        finally:\n",
    "            all_ratings.append(emp) \n",
    "            all_ratings.append(rev) \n",
    "            \n",
    "        all_ratings.append('1')\n",
    "        return all_ratings\n",
    "    except:\n",
    "        return [company_name,'','','','','','','','','','','','0']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent scraping: 65.92224540000001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "Loads the list of the companies from csv file,\n",
    "starts the driver, calls get_ratings() for each company,\n",
    "creates and cleans DataFrame with the results,\n",
    "saves results into companies_with_indeed_data.csv\n",
    "'''\n",
    "\n",
    "# read csv with just list of company names\n",
    "df_companies = pd.read_csv(\"data/companies.csv\")\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "# 1. start the driver\n",
    "binary = FirefoxBinary('C:\\\\Program Files\\\\Mozilla Firefox\\\\firefox.exe')\n",
    "driver = webdriver.Firefox(firefox_binary=binary)\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "result =[]\n",
    "# df_companies = df_companies[:2]\n",
    "\n",
    "for ii,i in df_companies.iterrows():\n",
    "    m = get_ratings(i[0]) \n",
    "    result.append(m)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "# done with that driver\n",
    "driver.close()\n",
    "\n",
    "print ('Time spent scraping:', elapsed )\n",
    "\n",
    "mt = pd.DataFrame(result,)\n",
    "mt.columns=['company','work_life','salary','job_security','management','culture','ceo','ceo_details',\n",
    "            'num_reviews','pay_details', 'num_employees', 'revinew','got_indeed_review']\n",
    "\n",
    "#the following is a fack, to make sure all nulls a set to Nan\n",
    "mt.to_csv(\"temp.csv\", index=False)\n",
    "mt = pd.read_csv(\"temp.csv\")\n",
    "\n",
    "# clean up data collected\n",
    "mt['num_reviews'].fillna('0 ', inplace = True)\n",
    "mt['num_reviews'] = [i.replace('See all ','') for i in mt['num_reviews']]\n",
    "mt['num_reviews'] = [i.split()[0] for i in mt['num_reviews']]\n",
    "mt['num_employees'].fillna(\"<dd></dd>\", inplace = True)\n",
    "mt['num_employees'] = [i.replace('<dd>','') for i in mt['num_employees']]\n",
    "mt['num_employees'] = [i.replace('</dd>','') for i in mt['num_employees']]\n",
    "\n",
    "mt.to_csv('data/companies_with_indeed_data.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
